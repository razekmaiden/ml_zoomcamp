{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78ac937b",
   "metadata": {},
   "source": [
    "# Homework\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539fcc91",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "In this homework, we'll build a model for predicting if we have an image of a dog or a cat. For this,\n",
    "we will use the \"Dogs & Cats\" dataset that can be downloaded from [Kaggle](https://www.kaggle.com/c/dogs-vs-cats/data). \n",
    "\n",
    "You need to download the `train.zip` file.\n",
    "\n",
    "If you have troubles downloading from Kaggle, use [this link](https://github.com/alexeygrigorev/large-datasets/releases/download/dogs-cats/train.zip) instead:\n",
    "\n",
    "```bash\n",
    "wget https://github.com/alexeygrigorev/large-datasets/releases/download/dogs-cats/train.zip\n",
    "```\n",
    "\n",
    "In the lectures we saw how to use a pre-trained neural network. In the homework, we'll train a much smaller model from scratch. \n",
    "\n",
    "**Note:** You don't need a computer with a GPU for this homework. A laptop or any personal computer should be sufficient. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419ee84b",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "The dataset contains 12,500 images of cats and 12,500 images of dogs. \n",
    "\n",
    "Now we need to split this data into train and validation\n",
    "\n",
    "* Create a `train` and `validation` folders\n",
    "* In each folder, create `cats` and `dogs` folders\n",
    "* Move the first 10,000 images to the train folder (from 0 to 9999) for boths cats and dogs - and put them in respective folders\n",
    "* Move the remaining 2,500 images to the validation folder (from 10000 to 12499)\n",
    "\n",
    "You can do this manually or with Python (check `os` and `shutil` packages)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8159d0b0",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "For this homework we will use Convolutional Neural Network (CNN. Like in the lectures, we'll use Keras.\n",
    "\n",
    "You need to develop the model with following structure:\n",
    "\n",
    "* The shape for input should be `(150, 150, 3)`\n",
    "* Next, create a covolutional layer ([`Conv2D`](https://keras.io/api/layers/convolution_layers/convolution2d/)):\n",
    "    * Use 32 filters\n",
    "    * Kernel size should be `(3, 3)` (that's the size of the filter)\n",
    "    * Use `'relu'` as activation \n",
    "* Reduce the size of the feature map with max pooling ([`MaxPooling2D`](https://keras.io/api/layers/pooling_layers/max_pooling2d/))\n",
    "    * Set the pooling size to `(2, 2)`\n",
    "* Turn the multi-dimensional result into vectors using a [`Flatten`](https://keras.io/api/layers/reshaping_layers/flatten/) layer\n",
    "* Next, add a `Dense` layer with 64 neurons and `'relu'` activation\n",
    "* Finally, create the `Dense` layer with 1 neuron - this will be the output\n",
    "    * The output layer should have an activation - use the appropriate activation for the binary classification case\n",
    "\n",
    "As optimizer use [`SGD`](https://keras.io/api/optimizers/sgd/) with the following parameters:\n",
    "\n",
    "* `SGD(lr=0.002, momentum=0.8)`\n",
    "\n",
    "\n",
    "For clarification about kernel size and max pooling, check [Week #11 Office Hours](https://www.youtube.com/watch?v=1WRgdBTUaAc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "258790ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from tensorflow.keras.applications.xception import preprocess_input\n",
    "#from tensorflow.keras.applications.xception import Xception\n",
    "#from tensorflow.keras.layers import Conv2D\n",
    "#from tensorflow.keras.layers import MaxPooling2D\n",
    "#from tensorflow.keras.layers import Flatten\n",
    "#from tensorflow.keras.layers import Dense\n",
    "#from tensorflow.keras.layers import ReLU\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "856aa894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataset already downloaded\n"
     ]
    }
   ],
   "source": [
    "## Download and unzip Dataset\n",
    "data = 'https://github.com/alexeygrigorev/large-datasets/releases/download/dogs-cats/train.zip'\n",
    "if not os.path.exists(\"train.zip\"):\n",
    "    print(\"[INFO] Downloading Dataset\")\n",
    "    !wget $data\n",
    "    shutil.unpack_archive(\"train.zip\", \"dataset\")\n",
    "else:\n",
    "    print(\"[INFO] Dataset already downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5107dcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Dataset\n",
    "\n",
    "## from imutils ---> https://github.com/PyImageSearch/imutils/blob/master/imutils/paths.py\n",
    "def list_files(basePath, validExts=None, contains=None):\n",
    "    # loop over the directory structure\n",
    "    for (rootDir, dirNames, filenames) in os.walk(basePath):\n",
    "        # loop over the filenames in the current directory\n",
    "        for filename in filenames:\n",
    "            # if the contains string is not none and the filename does not contain\n",
    "            # the supplied string, then ignore the file\n",
    "            if contains is not None and filename.find(contains) == -1:\n",
    "                continue\n",
    "\n",
    "            # determine the file extension of the current file\n",
    "            ext = filename[filename.rfind(\".\"):].lower()\n",
    "\n",
    "            # check to see if the file is an image and should be processed\n",
    "            if validExts is None or ext.endswith(validExts):\n",
    "                # construct the path to the image and yield it\n",
    "                imagePath = os.path.join(rootDir, filename)\n",
    "                yield imagePath\n",
    "\n",
    "\n",
    "def dataset_split(input_folder=\"dataset/train\", output_folder=\"dataset/validation\", thr=10000.0):\n",
    "    train_dog_folder = os.path.join(input_folder, \"dog\")\n",
    "    train_cat_folder = os.path.join(input_folder, \"cat\")\n",
    "    validation_dog_folder = os.path.join(output_folder, \"dog\")\n",
    "    validation_cat_folder = os.path.join(output_folder, \"cat\")\n",
    "    \n",
    "    if not os.path.exists(validation_dog_folder):\n",
    "        os.makedirs(validation_dog_folder)\n",
    "    if not os.path.exists(validation_cat_folder):\n",
    "        os.makedirs(validation_cat_folder)\n",
    "    if not os.path.exists(train_dog_folder):\n",
    "        os.makedirs(train_dog_folder)\n",
    "    if not os.path.exists(train_cat_folder):\n",
    "        os.makedirs(train_cat_folder)\n",
    "        \n",
    "    for file in list_files(input_folder, validExts=(\".jpg\")):\n",
    "        label = os.path.split(file)[-1].split(\".\")[0]\n",
    "        n_id = float(os.path.split(file)[-1].split(\".\")[1])\n",
    "        if n_id >= thr:\n",
    "            if label == \"dog\":\n",
    "                print(f\"[INFO] Moving {file} to {validation_dog_folder} folder\")\n",
    "                shutil.move(file, validation_dog_folder)\n",
    "            else:\n",
    "                print(f\"[INFO] Moving {file} to {validation_cat_folder} folder\")\n",
    "                shutil.move(file, validation_cat_folder)\n",
    "        else:\n",
    "            if label == \"dog\":\n",
    "                print(f\"[INFO] Moving {file} to {train_dog_folder} folder\")\n",
    "                shutil.move(file, train_dog_folder)\n",
    "            else:\n",
    "                print(f\"[INFO] Moving {file} to {train_cat_folder} folder\")\n",
    "                shutil.move(file, train_cat_folder)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24a8a496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "373fdab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(learning_rate=0.002):\n",
    "    #base_model = Xception(\n",
    "    #    weights='imagenet',\n",
    "    #    include_top=False,\n",
    "    #    input_shape=(150, 150, 3)\n",
    "    #)\n",
    "\n",
    "    #base_model.trainable = False\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    inputs = keras.Input(shape=(150, 150, 3))\n",
    "    #base = base_model(inputs, training=False)\n",
    "    #vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "\n",
    "    conv_2d = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "    reduced = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv_2d)\n",
    "    vectors = keras.layers.Flatten()(reduced)\n",
    "    dense_64 = keras.layers.Dense(64, activation='relu')(vectors)\n",
    "    outputs = keras.layers.Dense(1, activation='sigmoid')(dense_64)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.8)\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d376f5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-21 22:51:15.975484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-21 22:51:15.984798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-21 22:51:15.985347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-21 22:51:15.986350: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-21 22:51:15.986622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-21 22:51:15.986939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-21 22:51:15.987237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-21 22:51:16.471411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-21 22:51:16.471744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-21 22:51:16.472073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-21 22:51:16.472346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3028 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "model = make_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40fe601",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Since we have a binary classification problem, what is the best loss function for us?\n",
    "\n",
    "Note: since we specify an activation for the output layer, we don't need to set `from_logits=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ef3d839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ANSWER-1] For a binary classification problem the besst loss funtion is : BinaryCrossentropy\n"
     ]
    }
   ],
   "source": [
    "print(\"[ANSWER-1] For a binary classification problem the besst loss funtion is : BinaryCrossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf00f8a",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What's the total number of parameters of the model? You can use the `summary` method for that. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c391489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6880e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ANSWER-2] The total number of parameters is: 11,215,873\n"
     ]
    }
   ],
   "source": [
    "print(\"[ANSWER-2] The total number of parameters is: 11,215,873\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5fc93c",
   "metadata": {},
   "source": [
    "### Generators and Training\n",
    "\n",
    "For the next two questions, use the following data generator for both train and validation:\n",
    "\n",
    "```python\n",
    "ImageDataGenerator(rescale=1./255)\n",
    "```\n",
    "\n",
    "* We don't need to do any additional pre-processing for the images.\n",
    "* When reading the data from train/val directories, check the `class_mode` parameter. Which value should it be for a binary classification problem?\n",
    "* Use `batch_size=20`\n",
    "* Use `shuffle=True` for both training and validaition \n",
    "\n",
    "For training use `.fit()` with the following params:\n",
    "\n",
    "```python\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50\n",
    ")\n",
    "```\n",
    "\n",
    "Note `validation_steps=50` - this parameter says \"run only 50 steps on the validation data for evaluating the results\". \n",
    "This way we iterate a bit faster, but don't use the entire validation dataset.\n",
    "That's why it's important to shuffle the validation dataset as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e2b2dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# train dataset generation\n",
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    'dataset/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59b200fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# validation dataset generation\n",
    "val_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    'dataset/validation',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb853c91",
   "metadata": {},
   "source": [
    "### First training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eb92ae9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-21 22:51:17.977976: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2021-11-21 22:51:18.258688: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-11-21 22:51:18.259935: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.2.89, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 9s 76ms/step - loss: 0.7039 - accuracy: 0.5140 - val_loss: 0.6918 - val_accuracy: 0.5180\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.6903 - accuracy: 0.5240 - val_loss: 0.6871 - val_accuracy: 0.5460\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 0.6897 - accuracy: 0.5400 - val_loss: 0.6867 - val_accuracy: 0.5540\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 7s 73ms/step - loss: 0.6873 - accuracy: 0.5455 - val_loss: 0.6798 - val_accuracy: 0.5590\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 7s 71ms/step - loss: 0.6806 - accuracy: 0.5555 - val_loss: 0.6830 - val_accuracy: 0.5470\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 7s 73ms/step - loss: 0.6794 - accuracy: 0.5685 - val_loss: 0.6778 - val_accuracy: 0.5640\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 7s 72ms/step - loss: 0.6752 - accuracy: 0.5720 - val_loss: 0.6704 - val_accuracy: 0.5870\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 7s 73ms/step - loss: 0.6751 - accuracy: 0.5700 - val_loss: 0.6579 - val_accuracy: 0.6230\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 7s 72ms/step - loss: 0.6633 - accuracy: 0.5920 - val_loss: 0.6577 - val_accuracy: 0.5960\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 7s 73ms/step - loss: 0.6482 - accuracy: 0.6280 - val_loss: 0.6497 - val_accuracy: 0.6220\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(train_ds, steps_per_epoch=100, epochs=10, validation_data=val_ds, validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8081956d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(results.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e35d9c9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f429df1ab80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAA4G0lEQVR4nO3deVxU1f/H8ddhFwQXUFBQwRX3jVxKE7fSsrLSotLKFttsse1bv77t36W+9bWsLLOy5ZtmpZVWpqmJ+25uKAoqCiqLqGyyz/n9cUkRUQeYmTsMn+fj4SNm5t65nznpey7nnnuO0lojhBDCdbmZXYAQQgj7kqAXQggXJ0EvhBAuToJeCCFcnAS9EEK4OA+zC6hMUFCQDg8Pr9a+eXl5+Pn52bagWkra4lzSHueS9jjLFdpiy5Ytx7XWTSp7zSmDPjw8nM2bN1dr39jYWKKjo21bUC0lbXEuaY9zSXuc5QptoZQ6dKHXpOtGCCFcnAS9EEK4OAl6IYRwcU7ZR1+Z4uJiUlJSKCgouOh2DRo0YM+ePQ6qyvZ8fHwICwvD09PT7FKEEC6i1gR9SkoK/v7+hIeHo5S64HY5OTn4+/s7sDLb0VqTmZlJSkoKERERZpcjhHARtabrpqCggMDAwIuGfG2nlCIwMPCSv7UIIURV1JqgB1w65P9SFz6jEMKxalXQCyGEq1qVkMEXaw5SXGqx+XtL0Fvp1KlTfPjhh1Xe75prruHUqVO2L0gI4TJKLZrXf9nNl+sueM9TjUjQW+lCQV9aWnrR/RYuXEjDhg3tVJUQwhXM25rCvrRcnrm6A57uto/lWjPqxmzPPfcc+/fvp0ePHnh6elK/fn2aNWvGtm3b2L17N6NHjyY5OZmCggIef/xxJk6cCJydziE3N5eRI0cyYMAA1q5dS2hoKPPnz6devXomfzIhhJkKikt5Z8k+erRoyMguIXY5Rq0M+ld/jmP30exKXystLcXd3b3K79mpeQAvX9f5gq+/8cYb7Nq1i23bthEbG8u1117Lrl27zgyDnDlzJo0bNyY/P5/LLruMm2++mcDAwHPeIyEhgW+++YZPPvmEW265hXnz5jFu3Lgq1yqEcB2fr0niWFYB79zaw26DMWpl0DuDPn36nDPW/b333uPHH38EIDk5mYSEhPOCPiIigh49egDQu3dvkpKSHFWuEMIJnTpdxIexiQyJbEq/1oGX3qGaamXQX+zM21E3TJWf0jQ2NpalS5eybt06fH19iY6OrnQsvLe395mf3d3dyc/Pt3udQgjnNW15InmFJfxtRKRdjyMXY63k7+9PTk5Opa9lZWXRqFEjfH19iY+PZ/369Q6uTghR26ScPM2Xaw9xc68wOoTY9+S0Vp7RmyEwMJArrriCLl26UK9ePYKDg8+8NmLECKZPn063bt3o0KED/fr1M7FSIURtMGXJPpSCycPb2/1YEvRVMHv27Eqf9/b25rfffqv0tb/64YOCgti1a9eZ559++mmb1ydErXLyECx8Boa9DMEX7o51RbuPZvPjn0eYeGVrmje0/8g76boRQphj6SuQsBi+nwBFp82uxqHeXBRPgI8nDw9qe/bJgizISrHL8STohRCOd2QLxP0AbYfB8b2w+P/Mrshh1iYeZ8W+DB4Z3IYGvmXTkWsN8yfBjMFQmGvzY1oV9EqpEUqpvUqpRKXUcxfYJloptU0pFaeUWlH2XAul1HKl1J6y5x+3ZfFCiFpIa1jyMtRrDGM+h8sfgy2fw+4FZldmdxaL5o1F8YQ2rMed/cPPvrDxE9izAC5/FLzr2/y4lwx6pZQ7MA0YCXQCblNKdaqwTUPgQ+B6rXVnYGzZSyXAU1rrjkA/4JGK+woh6pjEZZC0CgY9Cz4BMORFaN4TFjxqt64LZ/HrzmPsSMniyeHt8fEsu7HzyFb4/QVoPwL6T7LLca05o+8DJGqtD2iti4A5wA0Vtrkd+EFrfRhAa51e9t9jWuutZT/nAHuAUFsVL4SoZSylsPRlaNgKou4xnvPwgps/g9Ji+OEBYxsXVFRi4a3Fe4kM8Wd0z7IYzD8F398Nfk1h9EfgZp/edGtG3YQCyeUepwB9K2zTHvBUSsUC/sBUrfVX5TdQSoUDPYENlR1EKTURmAgQHBxMbGzsOa83aNDgguPYyystLbVqO2dWUFBw3uevjtzcXJu8j6uQ9jiXGe0RnLqcjmm72N3xKdJXrzv3tTb30TF+Kge/epRD4bc4tC5HtMXSQ8UcPlHEk729WbVyBWhN57g3CcxKYVuPf5G9cYf9Dq61vugfjG6YT8s9Hg+8X2GbD4D1gB8QBCQA7cu9Xh/YAtx0qeNprendu7euaPfu3ec9V5ns7GyrtrM3Pz+/au9r7We9lOXLl9vkfVyFtMe5HN4eRflaT+ms9fSBWpeWnv+6xaL19/do/UojrQ9vcGhp9m6L7Pwi3eu133XMx+u0xWIxnlz/sdYvB2i9eqpNjgFs1hfIVGt+T0gBWpR7HAYcrWSbRVrrPK31cWAl0B1AKeUJzANmaa1/qOoXkRDCRWz6BLKSYdirlXdRKAWjpkCDUJh3rzHc0EV8svIAmXlFPDcy0pi4zAH98uVZE/SbgHZKqQillBcQA1S8PD4fGKiU8lBK+WJ07exRxlRsnwF7tNZTbFm4o/3tb387Zz76V155hVdffZWhQ4fSq1cvunbtyvz5802sUAgnln8KVr4NbYZAm8EX3s6nAdw8E7KOwC9PGiN0arn0nAI+WXWQa7s1o3uLhg7rly/vkn30WusSpdQkYDHgDszUWscppR4se3261nqPUmoRsAOwYHT17FJKDcDo6tmplNpW9pb/p7VeWKOqf3sOUndW+lK90hJwr8YNvyFdYeQbF3w5JiaGJ554gocffhiA7777jkWLFjF58mQCAgI4fvw4/fr14/rrr5d1X4WoaPU7UHDKOJu/lBaXweDn4Y9/QNuh0ON2u5dnT1OXJlBcauGZqzoYX1wLHoXsIzDhN/Bt7JAarErEsmBeWOG56RUevwW8VeG51YBLpF7Pnj1JT0/n6NGjZGRk0KhRI5o1a8bkyZNZuXIlbm5uHDlyhLS0NEJC7LN4gBC1UlYKbJgOXW+BZt2s22fAk7A/Fn59Glr0hcA2di3RXvZn5DJnUzJ39G1JeJAfbJhhjJe/6h/Qoo/D6qidc91c5Mw7347TFI8ZM4a5c+eSmppKTEwMs2bNIiMjgy1btuDp6Ul4eHil0xMLUact/zdoCwz5u/X7uLnDTR/DR1fA3Hvg3iXGMMxa5u3Fe/HxcOOxoe3K9cuPdEi/fHkyBUIVxMTEMGfOHObOncuYMWPIysqiadOmeHp6snz5cg4dss/CvkLUWmm7YftsuOx+aNSqavs2CIMbPoBj2+CP1+1Snj1tPXyS33alMvHKNgS55xv98vWDYfSHxoVnB5Kgr4LOnTuTk5NDaGgozZo144477mDz5s1ERUUxa9YsIiPtu3iAELXOslfBqz4MfKp6+3e8DnpPgLXvwf4/bFubHWmteWNhPEH1vblvQPjZfvkxMx3WL19e7ey6MdHOnWcvAgcFBbFu3bpKt8vNtf3ERELUKklrYN8iGPoS+NVgmbyr/wWH18GPD8JDa8EvyHY12smyPelsTDrB66O74Lf9c1P65cuTM3ohhO1pDUteAv9m0Pehmr2Xl68xRUL+KfjpYacfcllq0by5KJ7WQX7cFnrctH758iTohRC2t2cBHNkM0c8bQV1TIV3gqteN+es3fFzz97OjeVtSSEjP5fnBzfCYN8G0fvnyalXQayf/JreFuvAZhYsrLYalr0JQB+hxh+3et89E407SJS9e8D4as+UXlTJlyT56hDVgWOI/TO2XL6/WBL2Pjw+ZmZkuHYRaazIzM/Hx8TG7FCGqb+tXcGI/DHulejcvXohScMM0Yx77ufc45apUX6xNIjW7gHdbb0LtWWC0gUn98uXVmouxYWFhpKSkkJGRcdHtCgoKanVQ+vj4EBYWZnYZQlRPYS7EvgEt+kGHkbZ/f78guHE6/O9GY1Wq6961/TGq6WReER/GJnJPxEnCt/zL9H758mpN0Ht6ehIREXHJ7WJjY+nZs6cDKhJCnGfdNMhLh1u/tl+fdJvBcMVjsGaqMXdOp+vtc5wqmrY8EbfCLJ7LfdMp+uXLqzVdN0IIJ5ebYYx3jxwFLSsuWWFjg//uVKtSpZw8zVfrkvhfk6/xyjvqFP3y5UnQCyFsY+V/oDjf6Je2NydblWrK7/sY57aYbtkrnKZfvjwJeiFEzWXuh80zodd4CGrnmGMGtoFr34ZDq2GVebOg7z6aTeL2Vbzg8bVT9cuXJ0EvhKi5P/4B7l7GuHlH6n4bdBkDsf+G5I2OPXaZ9xdu5kOv91D+IU7VL1+eBL0QomaObIG4H6D/I+Dv4Cm6TV6Vam1CBtcf+hfN1Qncxn7uVP3y5UnQCyGqT2tY8jL4BsLlj5lTwzmrUk122BQJFotm549vMdJ9E6VDXnK6fvnyJOiFENWXuBSSVsGVz4JPgHl1/LUq1a55sG22Qw65auUSJuR9ytHgaDwHmPQlZyUJeiFE9VhKjbP5hq0g6h6zqzFWpQofCAufgeOJdj1UUe5J2q2YxEm3xgTf+blT9suXJ0EvhKieHd9BepwxDbEzrP7k5g43fmzUMu9eKCmyz3G05uhX99LEcpyUYdNw93POfvnyJOiFEFVXXADL/wnNekDnm8yu5qwGoXD9X6tSvWaXQxSs+Yjw9GV82+Aeel1+lV2OYWsS9EKIqtv0CWQlw/BXwc3JYqTjKKMrae37kLjMtu99ZCuey15kSWkvuo55AeXkXTZ/cbL/Q0IIp5d/Ela+bcwz0zra7Goqd9U/oUmksSpV7sUnQrRa/ilKv7uLNEtDfm//Mt1bNrLN+zqABL0QompWv2OMVx/2qtmVXJiXrzHfTEEWzH+k5kMutYYFkyDrCI+XPMojIy+zTZ0OIkEvhLBeVgqsnw7dboFm3cyu5uKCOxvrtNpiVaqNM2DPz7xZEkOnPsMID/KzTY0OIkEvhLDe8n8DGga/YHYl1ulzf81XpTqyFRa/wHbf/sxyu45HhzpoLh8bkqAXQlgnbTdsnw2X3Q+NWpldjXVquipV/in4/m4K6zXlzhMTmHhlW4Lqe9ulVHuyKuiVUiOUUnuVUolKqecusE20UmqbUipOKbWiKvsKIWqBZa+Clz9c+bTZlVTNX6tSHU+AxVWYdK2sX15nH+FV76fwrB/IfQMvvfiRM7pk0Cul3IFpwEigE3CbUqpThW0aAh8C12utOwNjrd1XCFELJK2BfYtgwBNOO3HXRf21KtWWL2D3Auv2KeuXT+j6NLOPhvD4sHb4edeaRfnOYc0ZfR8gUWt9QGtdBMwBbqiwze3AD1rrwwBa6/Qq7CuEcGZaw5KXwL859H3Q7GqqryqrUpX1y1vajeCRA/1pHeRHzGUtHFOnHVjz9RQKJJd7nAJUXCesPeCplIoF/IGpWuuvrNwXAKXURGAiQHBwMLGxsVaUdr7c3Nxq7+tqpC3OJe1xLmvbIyhjLV2ObCa+wyRS15oz57ut1At7gN5pT5A78xa29XgdlDtwblt4FOfSe8uTKM+GTC25lYSMPB7p4c2aVStNrLxmrAn6ym79qjgo1QPoDQwF6gHrlFLrrdzXeFLrGcAMgKioKB0dHW1FaeeLjY2luvu6GmmLc0l7nMuq9igthmlPQpNIIm95lUj32tl1cY7m0PCnB4l22wKDngXKtYXW8N14KMqkYPyv/PhNHj1a+PD0rZfXmrtgK2NN100KUP53ljDgaCXbLNJa52mtjwMrge5W7iuEcFZbv4QT+2Hoy+AKIQ/QPQa6joXYN+DwhnNfK+uXZ9irzDwURGp2Ac+PjKzVIQ/WBf0moJ1SKkIp5QXEABWvZswHBiqlPJRSvhjdM3us3FcI4YwKcyH2TWjZHzqMNLsa21EKrp0CDcJg3n3GEEo40y9P+5Gc7HY/H8XuZ2hkU/q2DjS1XFu4ZNBrrUuAScBijPD+Tmsdp5R6UCn1YNk2e4BFwA5gI/Cp1nrXhfa1z0cRQtjUummQlw7DX3P6+darzCcAbv4Mso1VqTyKc+H7u42lEEd/yLTY/eQVlvDsiEizK7UJq34X01ovBBZWeG56hcdvAW9Zs68QwsnlZsDa9yBylFMvkVcjLS6Dwf8Hf7xOr3oboDANJiwiucCHr9Yd4uZeYXQI8Te7SpuQO2OFEOdb8SYU58OwV8yuxL4GTIbwgfjmHzEmaWtxGVOW7EMpePKq9mZXZzMS9EKIc2Xuhy2fQ687Iaj2zetSJW7ucMtXxHV6Gvo/QtzRLH7adoQJV0TQrEE9s6uzGQl6IcS5/ngd3L0guo7MWOLbmIymA0Ep3ly0lwAfTx4a1MbsqmxKgl4IcdaRLRD3I/R/xLgwWYesSTzOyn0ZTBrclga+nmaXY1MS9EIIg9aw5GXwDYTLHzO7GoeyaM2/f9tDaMN6jO9fS2bmrAIJeiGEIXEpJK2CK581hh/WIRtTS9l1JJsnh7fHx9Pd7HJsToJeCAGWUuNsvlG4sbB2HVJUYmHeviIiQ/wZ3TPU7HLsQoJeCAE7voP0OBjyInh4mV2NQ72zdB8Z+ZrnRkbi7uZiN4aVkaAXoq4rLoDl/4RmPaDzTWZX41Bfrz/ER7H7GRTmwaD2Tcwux25cZJYiIUS1bZwBWclwwwfgVnfO/X6PS+Wl+bsYGtmU21vm1vqJyy6m7vxfFUKcL/8krPovtBkKraPNrsZhth4+yWNz/qRrWEPev72ny3bZ/EWCXoi6bPU7UJAFw181uxKHOZCRy71fbCI4wIfP7orC18v1OzZc/xMKISrlXZABm6ZDt1sgpKvZ5ThERk4hd32+ETel+HJCH4Lqe5tdkkNI0AtRR4UnzQY0DH7B7FIcIq+whHu+2MTxnCK+mdiP8CA/s0tyGOm6EaIuSosjJHU59JkIjVzvTtCKikstPDJ7K3FHs/jg9p70aNHQ7JIcSoJeiLpo6auUuvvCwKfMrsTutNa88ONOYvdm8M8buzK0Y7DZJTmcBL0Qdc2GjyFhMYdajQHfxmZXY3fvLk3gu80pPDakLbf1aWl2OaaQoBeiLtn3Oyx6DjpcS3KLG8yuxu7mbDzM1GUJjO0dxuThrrOQSFVJ0AtRV6TFwdx7ILgL3PwJKNebvKu85fHpvPDTLq5s34R/3dTVpW+IuhQJeiHqgpw0mH0reNeH278FL9cecbI9+RQPz9pKx2b+fHhHLzzd63bUyfBKIVxdcT7MuR1OZ8KE3yCgudkV2dWhzDzu+WITgfW9mHn3ZdT3lpiTFhDClVks8NNDxspRt34NzXuYXZFdZeYWctfMjZRqzZf39KGpv4/ZJTkFCXohXFnsv4ylAYe/Bh1HmV2NXeUXlXLvl5s5llXA7Pv70qZJfbNLchoS9EK4qu1zYOVb0HO8yy8NWFJq4dFv/mR7yik+uqM3vVu5/rDRqqjbVyiEcFWH1sKCRyF8IFw7BVx4xInWmpcXxLF0TxqvXt+ZEV3q1qLm1rAq6JVSI5RSe5VSiUqp5yp5PVoplaWU2lb256Vyr01WSsUppXYppb5RSkmnmRD2lLkf5twBDVvCrf9z+RWjPozdz6wNh3lwUBvu7B9udjlO6ZJBr5RyB6YBI4FOwG1KqU6VbLpKa92j7M9rZfuGAo8BUVrrLoA7EGOz6oUQ58o/aQyjRMPt30G9RmZXZFfztqTw1uK9jO7RnGev7mB2OU7LmjP6PkCi1vqA1roImANU5ZY6D6CeUsoD8AWOVr1MIcQllRbDd3fCySS4dRYEtjG7IrtauS+Dv83bwRVtA/nPmO64ufjiITVhzcXYUCC53OMUoG8l2/VXSm3HCPKntdZxWusjSqm3gcNAPvC71vr3yg6ilJoITAQIDg4mNjbW+k9RTm5ubrX3dTXSFudy6fbQmvb7PqT5sZXsiXyctKRiSIq96C61uT0OZZfy7w0FNPNz445W+axdvbJG71eb28IqWuuL/gHGAp+WezweeL/CNgFA/bKfrwESyn5uBPwBNAE8gZ+AcZc6Zu/evXV1LV++vNr7uhppi3O5dHuseU/rlwO0XvKK1bvU1vY4nJmno/6xRPf/11KdmpVvk/esrW1RHrBZXyBTrem6SQFalHscRoXuF611ttY6t+znhYCnUioIGAYc1FpnaK2LgR+Ay6v6ZSSEuIj4X+H3F6HTDTDkRbOrsatTp4u4+/ONFBaX8uU9fQgOkLEd1rAm6DcB7ZRSEUopL4yLqQvKb6CUClFlMwYppfqUvW8mRpdNP6WUb9nrQ4E9tvwAQtRpx7bDvPugeU8YPR3cXHfEdEFxKfd9uZnkE/l8cmcU7YL9zS6p1rhkH73WukQpNQlYjDFqZqbWOk4p9WDZ69OBMcBDSqkSjL74mLJfJTYopeYCW4ES4E9ghn0+ihB1TPZRmB0D9RrDbd+Al6/ZFdlNqUXzxJxtbDl8kg9u60Xf1oFml1SrWHVnbFl3zMIKz00v9/MHwAcX2Pdl4OUa1CiEqKgoD76JgcJsuGcR+LvuTUJaa17/ZTeL4lJ5cVQnru3WzOySah2ZAkGI2sZigR8mQupOuG0OhHQ1uyK7mrHyAF+sTeLeARHcOyDC7HJqJQl6IWqbZa9A/C8w4g1of7XZ1djV/G1H+Pdv8VzbrRkvXNPR7HJqLde9ciOEK9r6FayZClH3Qt8Hza7GrtYmHufp77fTJ6Ix/x0rN0TVhAS9ELXFwZXwy2RoMwRG/selJyrbcyybB/63hYggPz4ZH4WPp2sve2hvEvRC1AbHE+Hb8RDYFsZ+Ae6u2+t69FQ+Ez7fhK+3O19M6EMDX0+zS6r1JOiFcHanT8DsseDmYaz36tPA7IrsJiu/mLs/30heYQlfTOhD84b1zC7JJbjuaYEQrqCkCL4dB1lH4K6foVG42RXZTWFJKRO/2szB43l8OaEPHZsFmF2Sy5CgF8JZaQ0/Pw6H1sBNn0LLyuYSrJqC4lIS0nJJSM9hf2oJ/odOEhzgTVN/H7w8zPsF32LRPPXddjYcPMHUmB5c3jbItFpckQS9EM5q9RTYPhsGPQfdxlZpV601KSfziU/NIf5YNvGpOexJzSbpeB4WfXa7advWnvm5sZ8XwQE+BAd4E+xv/LdpgA8hAT5nng+s7427HUa//Pu3Pfyy4xjPjYzkhh6hNn//uk6CXghnFPcTLHsNuoyB6PMWdTtHTkEx+9Jy2HMsh/jUbOKP5bA3NYecwpIz27QK9CUyxJ/rujWnYzN/2gX7s3b9Rlq070J6diGp2QWkZReQll1Iek4Bu49mczy38JwvBQB3N0WT+t5nvgSCA7wJCfAp+/nsl0RDX0+UlaOCZq4+yCerDnJX/1Y8cGXrqraUsIIEvRDO5sgW+PEBCOsDN0w7M4yy1KJJyswjvizQ9xzLYW9aNskn8s/s6u/jQceQAG7sFUpkSACRzfzpEOyPn/f5/9ST/d2I7tD0gmWUlFrIzCsiLbuA1KwC0nIKSS/7QkjNLiT5xGk2J53g5Oni8/b18nAr95tBuS+BAB+alv03JMCHFfsyeP3X3VzdOZiXruts9ZeDqBoJeiGcyalk+OY2Sv2asrXf++zccMw4S081ztILSyyAcWbdOsiPHi0aEXNZSzo286dDSADNG/jYLCw93N3OhHS3sAtvV1BcSkZO4ZnfCNLO/HZgPN6Tmk3s3nTyikor3T+qVSOmxvS0S5eQMEjQC2GiohIL+zNyiU/N5kBKKmN33E/j4hxuLHyKhK/3AxDo50XHZgGM79eKyGYBRIb407Zpfae5icjH050WjX1p0fjis2fmFpac9yVQWGzhrstbOc1ncVUS9EI40M6ULNbsP37mAmliei4lFo0bFj7z+i+hbkl82vJNbmk7jMhm/kSGBNDE39vssm2ivrcH9ZvUp02T+maXUudI0AvhAKeLSvjPor18sTYJgOYNfIhsFsDgyKZEhvhz5YEpNNrxJ1zzNg/0ud/cYoXLkaAXws7WH8jk2bk7OHziNHdfHs5jQ9vR2M/r7AabPoMdn0Lfh0BCXtiBBL0QdlL+LL5lY1/mTOxHv4orIyUug4XPQLur4ep/mlOocHkS9ELYQcWz+GdHdMDXq8I/t/R4+P5uaNoRxnwGbnJBUtiHBL0QNmTVWTxA3nGYfQt4+BirRHnLQtfCfiTohbARq87iAYoLYM7tkJsGdy+Ehi0cX6yoUyTohaghq8/iwZiobMEkSN4AY7+EsN6OLVbUSRL0QtSA1WfxYIT88n/Bzu9hyIvQebRDaxV1lwS9ENVQpbN4AEspLHoONs6AHuNg4FOOK1bUeRL0QlRRlc7iAYryYN59sHchXP4oDHvNpdd7Fc5Hgl4IK1X5LB4gN90YXXNsO1zzttwQJUwhQS+EFap8Fg+QsRdmjTGGUsbMhg4jHVOsEBVYtXaYUmqEUmqvUipRKXXeKghKqWilVJZSalvZn5fKvdZQKTVXKRWvlNqjlOpvyw8ghD2dLirhlQVxxMxYD8Ccif145frOlw75pNXw2XBjKOXdv0rIC1Nd8oxeKeUOTAOGAynAJqXUAq317gqbrtJaj6rkLaYCi7TWY5RSXsDF5zIVwklU6yweYMf3MP9haBQBd3wPjVrZv1ghLsKarps+QKLW+gCAUmoOcANQMejPo5QKAK4E7gbQWhcBRdUtVghHqFZfPBjDJ1dPMZYAbDUAYr6Geo3sX7AQl6C01hffQKkxwAit9X1lj8cDfbXWk8ptEw3MwzjjPwo8rbWOU0r1AGZgfCl0B7YAj2ut8yo5zkRgIkBwcHDvOXPmVOsD5ebmUr++zHcN0hYVWdMe8SdK+WxnIRn5mmEtPRjb3gtvj0uPkFGWUtolTKf5sd9Ja3ol8ZGPod08bVW6Xcjfj7NcoS0GDx68RWsdVdlr1pzRV/a3vOK3w1agldY6Vyl1DfAT0K7s/XsBj2qtNyilpgLPAS+e94Zaz8D4UiAqKkpHR0dbUdr5YmNjqe6+rsa0trBYIG0XJK2CgyuN4YVD/g4t+zm+lnIu1h5nzuI3lp3Fj+9m3Vk8QGGOMTnZsaUw8GmCh/yd4FowfFL+rZzl6m1hTdCnAOUn4wjDOGs/Q2udXe7nhUqpD5VSQWX7pmitN5S9PBcj6IUr0RqO7zNC/eBK40Jk/gnjtcZtoKQAZl4NPcfD8NfAt7G59VZQ7b54gOxjMHsspO2G696D3nfZt1ghqsGav82bgHZKqQjgCBAD3F5+A6VUCJCmtdZKqT4Yo3kyyx4nK6U6aK33AkOxom9fODmt4eRBOFh2xp60ypigC6BBC+hwDUQMhPCB0CAUCnNhxZuw/kOI/xWueh163GH6TUMV++K/ndiPvtaexQOkxcGssVCQBXd8B22H2a9YIWrgkkGvtS5RSk0CFgPuwMyy/vcHy16fDowBHlJKlQD5QIw+2/n/KDCrbMTNAWCCHT6HsLesI2dD/eBKyEo2nq8fDBFXGn/CB0Kj8PMD3Lu+Ee7dY+CXJ2H+I/DnLBg1xZiL3QQ1OosH2L8cvrsTvPxgwm/QrJv9ihWihqz6m621XggsrPDc9HI/fwB8cIF9twGVXiAQTiw3/WyoH1wFJ/Ybz9drDOED4IrHIWIQBLWz/sw8uLMRittmwZIXYfoA6D8JBj1rBKYD1PgsHowvqZ8fg6AOxpl8gzD7FCuEjcidscKQfxKS1pztZ8/YYzzvHQCtroDL7jO6Y5p2Bjer7rOrnJsb9BpvdO8sfQnWvAu7foBr/mP3m4riT5Ty0rurqn8WrzXEvgEr3oDW0XDLV+DTwG71CmErEvR1VWEOHFoHSWXBfmwHoMHT1xgd0/1WozsmpDu42+GviV8g3DDNmMnxl8nwTQxEjoIRb9h8IY6jp/J5b1kCczYVVP8svqQIfn4cts82ri9cNxXcnXv4pBB/kaCvK4rzjcUu/jpjP7IVdCm4e0GLvhD9vBHsob3Bw8txdbXqDw+ugnXTjAu20/oYtfR7qMZBmp5dwLTliXyz0biecHUrD965d2DVzuIB8k/Bd+ONdhv8Alz5jOkXkoWoCgl6V2Wx0ODUbogtC/eUjVBaBMrdCPMBk42umBZ9wbOeubW6e8KAJ6DLTfDb34z+++3fwKh3qjX2PjO3kOkr9vPVukOUWjRjo8KYNKQdCds2VD3kTyUbI2syE2D0dOhxW5XrEcJsEvSuJjcD/vwfbPmcnqcOAwqadYe+DxgXT1v2c96FqBu2hNu+MYZgLny2ymPvT50uYsbKA3yxNomC4lJu7BnG40Pb0TLQmF4poar1HNsOs24xfhsa9wO0HlT1zySEE5CgdwVaw+H1sPkz2D3fOHNvNYDdzcbS6fpHa998K5HXGl9KFcfed7+90gvB2QXFfLbqIDNXHyS3qIRR3Zrz+NB2tG1ag1va9/1u3O1arxHcu9i0YaBC2IIEfW1WkA07voXNMyF9tzFCpvcEiLoHmkaSHhtLp9oW8n+pdOz913DtFAjuBEBeYQlfrE1ixsoDZOUXc3XnYCYPb09kSEDNjr15Jvz6tDEc9PbvIKCZDT6QEOaRoK+NUnfCps9gx3dQnGd0zVz3HnQd47Dx6A5Tcez9xwMp6fsw//OK4YPVR8nMK2JIZFOeHN6eLqE1HOposcAfr8Hqd6DdVTDmc+MLR4haToK+tigugN0/GQGfshE8fKDLGOPsPbSXa48CKRt7X9j2ag5/+wzt1r3HcD2bk0GPEn3XXfRqaYPfWkoK4aeHYNc847eia962z7BSIUwgf5OdXeZ+2PK5cTdm/gkIbAtX/9sY/VFbu2WqqLjUwtwtKby/LIGjWbcwPnQAz5fO4MnMl2HNRgh4s2Zj70+fgDl3wOG1MOwVuOIJ1/7iFHWOBL0zKi2BfYuMi6v7/zCGRHYcBVH3GmPd60gIlZRa+GnbUd5blsDhE6fp2bIh/xnTnSvaBqIsd1cYe/8c9Hu46mPvTxw0hk+eOgQ3f2Z0fwnhYiTonUn2Mdj6JWz5EnKOgn9ziP4/6HVnnbogaLFoft5xlKlLEzhwPI/OzQOYeXcUgzs0Rf31JXfe2PuXYPsc42JtKyuXJU7ZArNvAUsJ3DkfWl1ut88khJkk6M2mNRxcYfS9x/9q3K3aZghc8xa0H1Gn+om11iyOS+WdJQnsTcuhQ7A/08f15urOwWcDvqKKY+8/HwE9x8Gw14xpFi4k/leYey/Ubwp3zIUm7e3zoYRwAnUnRZzN6RPG3Z+bZ0JmojErZP+HjQuBgW3Mrs6htNb8EZ/OlCX7iDuaTesmfrx3W09GdW2Gm5uV3VTnjb1faNxo1eOO88fer58Oi54zLmLfNscIeyFcmAS9I2ltzDGz+TNjdEdJAYT1gRs/hk6jwdPH7AodSmvN6sTj/Pf3fWxLPkXLxr78d2x3bujRHA/3asyQWXHs/YJJxrDMv8be61JY9LzxRdDhWrj5U/Dytf0HE8LJSNA7QlEe7JxrBPyx7eDpB91vg8vuhZCuZldnig0HMvnv7/vYmHSC5g18+PdNXRnTOwzP6gR8RZWMvaffw3TetwmOr4O+D8LV/wI395ofS4haQILentLjja6Z7XOgMAuadjLGZ3e7FXxqePdmLbX18Emm/L6P1YnHaervzavXdyamTwu8PWwcuhXnvV/7HkEoY2hq/4dteywhnJwEva1pDfG/GP3Ah1Yb0wB3usEYGtmyX50ZGlnRzpQspizZy/K9GQT6efH3azsyrl8rfDztfFb917z3vSewbfN6ekrIizpIgt7Wdn4PP9wPDVsZN9/0HA9+QWZXZYqC4lI2HDzB7A2HWByXRoN6njw7ogN39Q/Hz9vBf/XCoshKzHXsMYVwEhL0tnQq2ZgMq0VfuHthnRoaCcbF1YPH81ixL4MV+zJYfyCTgmIL/t4ePDGsHfcMiCDAR1ZlEsLR6lYS2ZPFYsyVokuNUTR1JOTzCktYtz+TFfsyiN2XTvKJfAAigvyIuawlgzo0oV9EIPW85MKnEGapG2nkCOs/hKRVcP370DjC7GrsRmvN3rQcVuw1zto3JZ2guFTj6+XO5W0CmTiwNVe2b0KrQBebRVOIWkyC3hbSdsOyV42x2T3Hm12NzWXlF7Mm8fiZcE/NLgCgQ7A/E66IILp9E3qHN7L9yBkhhE1I0NdUSSH8MBF8GsB1U11iVI3Fook7mk3s3nRW7Mvgz+RTlFo0/j4eDGwXxKD2TbiyfROaNTB5rVkhhFUk6Gtq+T8hbWfZrfRNzK6m2jJzC1mVcJwV+zJYuS+DzLwiALqGNuChQW0Y1KEJPVs0rN4dq0IIU0nQ10TSGljzHvS6CzqMNLuaKikptbA95dSZ7pgdR7LQGhr5enJl+yZEd2jCwHZNCKrvbXapQogasirolVIjgKmAO/Cp1vqNCq9HA/OBg2VP/aC1fq3c6+7AZuCI1npUzct2AgXZ8OOD0CjcuJ2+FkjLLjgz9HF1wnGy8otxU9CzZSMmD2vPoPZN6BLaAHdrJxITQtQKlwz6spCeBgwHUoBNSqkFWuvdFTZddZEQfxzYA7jOff+//Q2yU+CexU67rmiJRbN2v9Eds2JvBvGpOQA09ffmqk7BDOrQhIFtm9DAV8a2C+HKrDmj7wMkaq0PACil5gA3ABWDvlJKqTDgWuCfwJPVrNO57J4P22fDlc9Aiz5mV1Op7zYn8/Ifp8kv2YCnuyKqVWOeGxnJoPZNiAzxv/D87kIIl2NN0IcCyeUepwB9K9muv1JqO3AUeFprHVf2/LvAs4D/xQ6ilJoITAQIDg4mNjbWitLOl5ubW+19reFVeILLNj1GQf02bKUf2o7Hqo5Si+a7vUUsPlRCuwaaka196BjoTj2PAtDJpO1NJm2v2VWaw95/N2obaY+zXL0trAn6yk79dIXHW4FWWutcpdQ1wE9AO6XUKCBda72lrB//grTWM4AZAFFRUTo6+qKbX1BsbCzV3feStDbWF6UYz7vmMMjJViXKOl3MpG+2surQaSZcEc4Av3SGDhlsdllOw65/N2ohaY+zXL0trBkrlwK0KPc4DOOs/QytdbbWOrfs54WAp1IqCLgCuF4plQTMAYYopb62ReGm2PwZJC6B4a873dJziem5jP5wDesPZPLmzV15+brOclFVCAFYF/SbMM7OI5RSXkAMsKD8BkqpEFXW6auU6lP2vpla6+e11mFa6/Cy/f7QWo+z6SdwlOOJsPjv0GYo9Lnf7GrOsTw+nRunrSGnoJhv7u/HrZe1NLskIYQTuWTXjda6RCk1CViMMbxyptY6Tin1YNnr04ExwENKqRIgH4jRWlfs3qm9SouNqYc9vI25zZ3kQqbWmhkrD/DGong6hgTwyV1RhDaUu1WFEOeyahx9WXfMwgrPTS/38wfAB5d4j1ggtsoVOoOVb8PRrTD2CwhoZnY1gDHX+/M/7OTHP49wbddmvDW2G75ecv+bEOJ8kgyXkrIZVr4F3WKg841mVwMYNz5N/N8Wtief4qnh7Zk0pK0MlxRCXJAE/cUU5RkTlgU0h2v+Y3Y1AGxLPsXErzaTW1jC9HG9GdElxOyShBBOToL+Yn7/O5w4AHf9bMxOabIf/0zhb/N20tTfmx/uvZzIENe50VgIYT8S9Bey73fYPBMufxQiBppaSqlF85/F8Xy84gB9Ixrz0bjeNPbzMrUmIUTtIUFfmbxMmP8INO0MQ140tZTsgmIe/+ZPlu/NYFy/lrx8XWc8ZapgIUQVSNBXpDX8/BgUnILxPxpDKk1y8Hge9325iUOZp3l9dBfG92tlWi1CiNpLgr6ibbMh/hfj7teQLqaVsSohg0dmbcXdTfG/e/vSv02gabUIIWo3CfryTiYZ0w+3GgD9HzGlBK01X6xN4h+/7qFtk/p8elcULRr7mlKLEMI1SND/xVIKPz5k3PV640fg5viFrgtLSnnppzi+3ZzMVZ2CmXJrD+p7y/8iIUTNSIr8Ze17cHgt3PgxNHT8XDEZOYU89PUWNh86yWND2vLEsPa4yaRkQggbkKAHOLYD/vgndLoBut3q8MPvOpLFxK82c+J0ER/c3pNR3Zo7vAYhhOuSoC8uMO5+9Q2EUe86fMKyX3cc46nvt9HY14u5D15Ol1Dzb8wSQrgWCfplr0HGHhg3D3wbO+ywFovm3aX7eO+PRHq3asT0cb1p4m/eUE4hhOuq20F/IBbWT4PL7oe2wxx22LzCEiZ/u43fd6dxS1QYr4/ugreH4y/+CiHqhrob9Pmn4KeHIbAdDH/NYYdNPnGa+7/azL60HF6+rhN3Xx4uM08KIeyq7gb9wqchNw3uXQJejhmnvm5/Jg/P2kKpRfPlPX0Y2K6JQ44rhKjb6mbQ75wLO7+HwS9AaC+HHPLr9Yd4ZUEcrQJ9+fSuy4gI8nPIcYUQou4FffZR+PVJCI2CAU/a/XDFpRZe/TmOr9cfZnCHJky9rScBPp52P64QQvylbgW9xQI/PWSsAXvTDHC378c/kVfEw7O2sP7ACR4c1IZnru6Au9wEJYRwsLoV9BtnGCNtRr0LgW3seqj41Gzu+3Iz6TmFvHtrD0b3DLXr8YQQ4kLqTtCnx8PSl6Hd1dD7brseanFcKpO/3Ya/jwffP9Cf7i0a2vV4QghxMXUj6EuK4MeJ4OUH179vt7tfdx3J4p0l+1gWn073Fg2ZMb43wQE+djmWEEJYq24E/Yo34Nh2uHUW+Afb/O33pubwzpJ9LIpLpUE9T565ugP3DojAx1NughJCmM/1g/7welj9DvQcBx1H2fSt92fkMnVpAj/vOEp9Lw8eH9qOewdGyKgaIYRTce2gL8yBHx+ABi1gxBs2e9vDmaeZuiyBH/9MwdvDnYcGtWHila1p6CsLdgshnI9VQa+UGgFMBdyBT7XWb1R4PRqYDxwse+oHrfVrSqkWwFdACGABZmitp9qmdCsseh5OHYYJv4G3f43f7uipfN7/I5HvNyfj7qa454oIHoxuQ1B9mYxMCOG8Lhn0Sil3YBowHEgBNimlFmitd1fYdJXWumLfSAnwlNZ6q1LKH9iilFpSyb62F/8r/Pk/46aolv1q9Fbp2QVMW57INxuTAbijb0seHtxWLrQKIWoFa87o+wCJWusDAEqpOcANwCXDWmt9DDhW9nOOUmoPEGrNvjWSmw4LHoOQbhD9fLXfJjO3kOkr9vPVukOUWjRjo8KYNKQdoQ3r2bBYIYSwL2uCPhRILvc4BehbyXb9lVLbgaPA01rruPIvKqXCgZ7AhuqVaiWtYcGjRv/8TZ+AR9X7zU+dLmLGygN8sTaJguJSbuwZxuND29EyUBbpFkLUPtYEfWWDznWFx1uBVlrrXKXUNcBPQLszb6BUfWAe8ITWOrvSgyg1EZgIEBwcTGxsrBWlna9x0s9waBEJbe/jyO5U2J1q9b6nizW/HypmcVIxBSXQJ8SdG9rWo3n9kxzYuZED1arIPLm5udVuR1ck7XEuaY+zXL0trAn6FKBFucdhGGftZ5QPb631QqXUh0qpIK31caWUJ0bIz9Ja/3Chg2itZwAzAKKionR0dLT1n+IvmfspXTkLIgbR7va3aOfmZtVueYUlfLE2iRlrD5CVX8zVnYOZPLw9kSEBVa/BicTGxlKtdnRR0h7nkvY4y9Xbwpqg3wS0U0pFAEeAGOD28hsopUKANK21Vkr1AdyATGWsqPEZsEdrPcW2pVdQWgI/PoDFzR330R+BFSFfUFzK1+sP8VHsfjLzihgS2ZQnh7eXdVuFEC7lkkGvtS5RSk0CFmMMr5yptY5TSj1Y9vp0YAzwkFKqBMgHYspCfwAwHtiplNpW9pb/p7VeaPNPUnwa/JqQ0O5BOjW4+ARihSWlzNmYzLTliaTnFDKgbRBPXtWeXi0b2bwsIYQwm1Xj6MuCeWGF56aX+/kD4INK9ltN5X38tucTADGzSV+xgk4X2KS41MLcLSm8vyyBo1kF9AlvzPu39aRv60CHlCiEEGZwrTtjLzBZWUmphZ+2HeW9ZQkcPnGaHi0a8uaYbgxoGyTrtQohXJ5rBX0FFovml53HeHfpPg5k5NG5eQAz745icIemEvBCiDrDJYNea83iuFTeWZLA3rQcOgT7M31cb67uHCwBL4Soc1wq6LXWbEsv4a33VxN3NJvWTfx477aejOraDDdZwk8IUUe5TNBnFxRz52cb2ZZcSIvGbrw9tjujezTHw926sfRCCOGqXCbo/b09CA/0pUfAaV64PRpPCXghhACMG5tcglKKd2N6Et3CU0JeCCHKkUQUQggXJ0EvhBAuToJeCCFcnAS9EEK4OAl6IYRwcRL0Qgjh4iTohRDCxUnQCyGEi1NaV1z+1XxKqQzgUDV3DwKO27Cc2kza4lzSHueS9jjLFdqilda6SWUvOGXQ14RSarPWOsrsOpyBtMW5pD3OJe1xlqu3hXTdCCGEi5OgF0IIF+eKQT/D7AKciLTFuaQ9ziXtcZZLt4XL9dELIYQ4lyue0QshhChHgl4IIVycywS9UmqEUmqvUipRKfWc2fWYSSnVQim1XCm1RykVp5R63OyazKaUcldK/amU+sXsWsymlGqolJqrlIov+zvS3+yazKSUmlz272SXUuobpZSP2TXZmksEvVLKHZgGjAQ6AbcppTqZW5WpSoCntNYdgX7AI3W8PQAeB/aYXYSTmAos0lpHAt2pw+2ilAoFHgOitNZdAHcgxtyqbM8lgh7oAyRqrQ9orYuAOcANJtdkGq31Ma311rKfczD+IYeaW5V5lFJhwLXAp2bXYjalVABwJfAZgNa6SGt9ytSizOcB1FNKeQC+wFGT67E5Vwn6UCC53OMU6nCwlaeUCgd6AhtMLsVM7wLPAhaT63AGrYEM4POyrqxPlVJ+ZhdlFq31EeBt4DBwDMjSWv9ublW25ypBryp5rs6PG1VK1QfmAU9orbPNrscMSqlRQLrWeovZtTgJD6AX8JHWuieQB9TZa1pKqUYYv/1HAM0BP6XUOHOrsj1XCfoUoEW5x2G44K9fVaGU8sQI+Vla6x/MrsdEVwDXK6WSMLr0hiilvja3JFOlACla679+w5uLEfx11TDgoNY6Q2tdDPwAXG5yTTbnKkG/CWinlIpQSnlhXExZYHJNplFKKYw+2D1a6ylm12MmrfXzWuswrXU4xt+LP7TWLnfGZi2tdSqQrJTqUPbUUGC3iSWZ7TDQTynlW/bvZigueHHaw+wCbEFrXaKUmgQsxrhqPlNrHWdyWWa6AhgP7FRKbSt77v+01gvNK0k4kUeBWWUnRQeACSbXYxqt9Qal1FxgK8ZotT9xwekQZAoEIYRwca7SdSOEEOICJOiFEMLFSdALIYSLk6AXQggXJ0EvhBAuToJeCCFcnAS9EEK4uP8HB6eYmVe8lSEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results.history['accuracy'], label=('train'))\n",
    "plt.plot(results.history['val_accuracy'], label=('val'))\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2a8252",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "What is the median of training accuracy for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10e3b329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ANSWER-3] The median of training accuracy is: 0.56\n"
     ]
    }
   ],
   "source": [
    "train_median_acc = round(np.median(results.history['accuracy']), 2)\n",
    "print(f\"[ANSWER-3] The median of training accuracy is: {train_median_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ca74ff",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "What is the standard deviation of training loss for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "069c77e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ANSWER-4] The standard deviation of training loss is: 0.014680980486043278\n"
     ]
    }
   ],
   "source": [
    "train_std_loss = np.std(results.history['loss'])\n",
    "print(f\"[ANSWER-4] The standard deviation of training loss is: {train_std_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570028d3",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "For the next two questions, we'll generate more data using data augmentations. \n",
    "\n",
    "Add the following augmentations to your training data generator:\n",
    "\n",
    "* `rotation_range=40,`\n",
    "* `width_shift_range=0.2,`\n",
    "* `height_shift_range=0.2,`\n",
    "* `shear_range=0.2,`\n",
    "* `zoom_range=0.2,`\n",
    "* `horizontal_flip=True,`\n",
    "* `fill_mode='nearest'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d0f5e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# train dataset generation\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    'dataset/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0af0cb",
   "metadata": {},
   "source": [
    "### Question 5 \n",
    "\n",
    "Let's train our model for 10 more epochs using the same code as previously.\n",
    "Make sure you don't re-create the model - we want to continue training the model\n",
    "we already started training.\n",
    "\n",
    "What is the mean of validation loss for the model trained with augmentations?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a261231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 14s 145ms/step - loss: 0.6710 - accuracy: 0.5940 - val_loss: 0.6665 - val_accuracy: 0.5830\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 15s 152ms/step - loss: 0.6800 - accuracy: 0.5715 - val_loss: 0.6572 - val_accuracy: 0.6140\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.6711 - accuracy: 0.5850 - val_loss: 0.6588 - val_accuracy: 0.5910\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 0.6686 - accuracy: 0.5730 - val_loss: 0.6451 - val_accuracy: 0.6200\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 15s 147ms/step - loss: 0.6653 - accuracy: 0.5935 - val_loss: 0.6372 - val_accuracy: 0.6270\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 0.6693 - accuracy: 0.5825 - val_loss: 0.6479 - val_accuracy: 0.6240\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 0.6633 - accuracy: 0.6000 - val_loss: 0.6737 - val_accuracy: 0.5900\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 0.6719 - accuracy: 0.5800 - val_loss: 0.6432 - val_accuracy: 0.6270\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 20s 198ms/step - loss: 0.6605 - accuracy: 0.5960 - val_loss: 0.6485 - val_accuracy: 0.6310\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.6544 - accuracy: 0.5940 - val_loss: 0.6572 - val_accuracy: 0.5740\n"
     ]
    }
   ],
   "source": [
    "results_2 = model.fit(train_ds, steps_per_epoch=100, epochs=10, validation_data=val_ds, validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4657a9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ANSWER-5] The mean of validation loss  loss is: 0.653546953201294\n"
     ]
    }
   ],
   "source": [
    "val_mean_loss = np.mean(results_2.history['val_loss'])\n",
    "print(f\"[ANSWER-5] The mean of validation loss  loss is: {val_mean_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbebf77c",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "What's the average of validation accuracy for the last 5 epochs (from 6 to 10)\n",
    "for the model trained with augmentations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5184c84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ANSWER-6] The mean of validation accuracy is: 0.6091999888420105\n"
     ]
    }
   ],
   "source": [
    "val_mean_acc = np.average(results_2.history['val_accuracy'][5:])\n",
    "print(f\"[ANSWER-6] The mean of validation accuracy is: {val_mean_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
